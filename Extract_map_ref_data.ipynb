{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import traceback\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#source = \"/gpfs/glad3/HLSDIST/testing/TSmodels/230612\"#TSmodels/1_shutdown5obs3months\"#\"/gpfs/glad3/HLSDIST/VFModel/Drone/LP-DAAC\"#\"/gpfs/glad3/HLSDIST/LP-DAAC\"\n",
    "source = \"/gpfs/glad3/HLSDIST/Validation\"\n",
    "alertsource = \"/gpfs/glad3/HLSDIST/testing/v1sample/DIST-ALERT_v1\"#LP-DAAC/DIST-ALERT_v1\"\n",
    "ANNname = \"v1sample\"\n",
    "outfolder = \"../mapLabels\"+ANNname#_newVF\"\n",
    "#os.makedirs(outfolder)\n",
    "ANNlayers = ['VEG-DIST-STATUS','VEG-ANOM-MAX','VEG-IND-MAX','VEG-DIST-CONF','VEG-DIST-DATE','VEG-DIST-DUR','VEG-DIST-COUNT','GEN-DIST-STATUS','GEN-ANOM-MAX','GEN-DIST-CONF','GEN-DIST-DATE','GEN-DIST-DUR','GEN-DIST-COUNT']\n",
    "ALERTlayers = ['VEG-DIST-STATUS','VEG-ANOM','VEG-IND','VEG-HIST','VEG-ANOM-MAX','VEG-DIST-CONF','VEG-DIST-DATE','VEG-DIST-COUNT','VEG-DIST-DUR','VEG-LAST-DATE','GEN-DIST-STATUS','GEN-ANOM','GEN-ANOM-MAX','GEN-DIST-CONF','GEN-DIST-DATE','GEN-DIST-COUNT','GEN-DIST-DUR','GEN-LAST-DATE']\n",
    "startdate = datetime.datetime.strptime(\"2020-12-31\",\"%Y-%m-%d\")\n",
    "\n",
    "sampleDict = {}\n",
    "sampleFull = {}\n",
    "with open ('sampledpixels1214.csv','r') as dat:\n",
    "  lines = dat.readlines()[1:]\n",
    "  for l in lines:\n",
    "    (ID,Stratum,Long,Lat,zone,x,y,pixel,pline,centxUTM,centyUTM,MGRS) = l.strip().split(',')\n",
    "    sampleDict[ID] = ','.join([Long,Lat,zone,centxUTM,centyUTM])\n",
    "    sampleFull[ID] = l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractALERTsingle(line):#(ID,Long,Lat,MGRS):\n",
    "  (ID,Stratum,Long,Lat,zone,x,y,pixel,pline,centxUTM,centyUTM,MGRS) = str(line).split(',')\n",
    "  #outfolder = \"sample_v1\"#\"\"testPixels2023\"\n",
    "  #ANNname = \"\"\n",
    "  print(ID)\n",
    "  Long = str(Long)\n",
    "  Lat = str(Lat)\n",
    "  with open(outfolder+'/'+ID+\"_DIST-ALERT_\"+ANNname+\".csv\",'w') as alertcsv:\n",
    "    alertcsv.write(\"granuleID,SensingTime,ProductionTime,VEG-DIST-STATUS,VEG-ANOM,VEG-IND,VEG-HIST,VEG-ANOM-MAX,VEG-DIST-CONF,VEG-DIST-DATE,VEG-DIST-COUNT,VEG-DIST-DUR,VEG-LAST-DATE,GEN-DIST-STATUS,GEN-ANOM,GEN-ANOM-MAX,GEN-DIST-CONF,GEN-DIST-DATE,GEN-DIST-COUNT,GEN-DIST-DUR,GEN-LAST-DATE\\n\")\n",
    "    tilepath = MGRS[0:2]+'/'+MGRS[2:3]+'/'+MGRS[3:4]+'/'+MGRS[4:5]\n",
    "    response = subprocess.run([\"ls \"+alertsource+\"/202[1-2]/\"+tilepath+\"/DIST-ALERT*/OPERA*VEG-DIST-STATUS.tif 2>/dev/null\"], capture_output=True,shell=True)\n",
    "    Tgranlist = str(response.stdout.decode())\n",
    "    Tgranlist = Tgranlist.strip().split('\\n')\n",
    "    granlist = []\n",
    "    for filepath in Tgranlist:\n",
    "      folders = filepath.split('/')\n",
    "      gid = folders[-1]\n",
    "      (gid,temp)= gid.split('.')\n",
    "      granlist.append(gid+\",\"+filepath)\n",
    "      #print(granlist)\n",
    "    for line in granlist:\n",
    "      (gID,granpath) = line.split(',')\n",
    "      #(p1,p2) = granpath.split('//')\n",
    "      #granpath = p1+'/DIST-ALERT/'+p2\n",
    "      folders = granpath.split('/')\n",
    "      (sOPERA,sL3,sDIST,sTtile,ssensingTime,sProdTime,ssatellite,sres,sDISTversion,tlayer)=gID.split('_')\n",
    "      ODIST_ID = '_'.join([sOPERA,sL3,sDIST,sTtile,ssensingTime,sProdTime,ssatellite,sres,sDISTversion])\n",
    "      granpath = '/'.join(folders[0:-1])+\"/\"+ODIST_ID\n",
    "      stime = datetime.datetime.strptime(ssensingTime,\"%Y%m%dT%H%M%SZ\")\n",
    "      ptime = datetime.datetime.strptime(sProdTime,\"%Y%m%dT%H%M%SZ\")\n",
    "      alertcsv.write(','.join([gID,stime.strftime(\"%Y%m%d\"),str(ptime)]))\n",
    "      for layer in ALERTlayers:\n",
    "        #print(\"gdallocationinfo -wgs84 -valonly \" + granpath+'_'+layer+\".tif \"+Long+\" \"+Lat)\n",
    "        response = subprocess.run([\"gdallocationinfo -wgs84 -valonly \" + granpath+'_'+layer+\".tif \"+Long+\" \"+Lat], capture_output=True,shell=True)\n",
    "        #print(\"gdallocationinfo -wgs84 -valonly \" + granpath+'_'+layer+\".tif \"+Long+\" \"+Lat)\n",
    "        value = str(response.stdout.decode().strip()).split('\\n')[0]\n",
    "        #print(value)\n",
    "        if layer == \"VEG-DIST-DATE\" or layer == \"GEN-DIST-DATE\":\n",
    "          if int(value) > 0:\n",
    "            date = startdate+datetime.timedelta(days = int(value))\n",
    "            value = date.strftime(\"%Y%m%d\")\n",
    "          else:\n",
    "            value = \"NA\"\n",
    "        alertcsv.write(','+str(value))\n",
    "        #print(','+str(value),end='')\n",
    "      alertcsv.write(\"\\n\")\n",
    "      #print()\n",
    "        \n",
    "def processQueue(procID,queue,sampletable):\n",
    "  Nprocess = 0\n",
    "  while not queue.empty():\n",
    "    ID = queue.get().strip()\n",
    "    try:\n",
    "      extractALERTsingle(sampletable[ID])\n",
    "      #extractVFsingleBaselineTight(sampletable[ID])\n",
    "      #extractVFsingleBaseline(sampletable[ID])\n",
    "      Nprocess +=1\n",
    "    except:\n",
    "      traceback.print_exc()\n",
    "  return Nprocess\n",
    "\n",
    "def extractALERT():\n",
    "  pixelqueue = multiprocessing.Queue()\n",
    "  sampletable = {}\n",
    "  for line in lines:\n",
    "    (ID,Stratum,Long,Lat,zone,x,y,pixel,pline,centxUTM,centyUTM,MGRS) = line.strip().split(',')\n",
    "    sampletable[ID] = line.strip()\n",
    "  for ID in range(1,301):\n",
    "    pixelqueue.put(str(ID))\n",
    "  processes = []\n",
    "  for procID in range(1,61):\n",
    "    proc = multiprocessing.Process(target=processQueue,args=(str(procID),pixelqueue,sampletable))\n",
    "    processes.append(proc)\n",
    "    proc.start()\n",
    "  for p in processes:\n",
    "    p.join()\n",
    "  pixelqueue.close()\n",
    "  pixelqueue.join_thread()  \n",
    "  print(\"ALERT done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "15\n",
      "16\n",
      "17\n",
      "11\n",
      "12\n",
      "18\n",
      "19\n",
      "13\n",
      "20\n",
      "14\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "ALERT done\n"
     ]
    }
   ],
   "source": [
    "extractALERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMapTimeSeriesDaily(layer,nodatavalue):\n",
    "  nodatavalue = str(nodatavalue)\n",
    "  layers = ['granuleID','sensingTime','ProductionTime','VEG-DIST-STATUS','VEG-ANOM','VEG-IND','VEG-HIST','VEG-ANOM-MAX','VEG-DIST-CONF','VEG-DIST-DATE','VEG-DIST-COUNT','VEG-DIST-DUR','VEG-LAST-DATE','GEN-DIST-STATUS','GEN-ANOM','GEN-ANOM-MAX','GEN-DIST-CONF','GEN-DIST-DATE','GEN-DIST-COUNT','GEN-DIST-DUR','GEN-LAST-DATE']\n",
    "  #layers = ['granuleID','sensingTime','ProductionTime','VEG-DIST-STATUS','VEG-ANOM','VEG-IND','VEG-DIST-CONF','VEG-DIST-DATE','VEG-DIST-DUR','GEN-DIST-STATUS','GEN-ANOM','GEN-DIST-CONF','GEN-DIST-DATE','GEN-DIST-DUR']\n",
    "  layerIndex = layers.index(layer)\n",
    "  startday = datetime.datetime.strptime('20211001','%Y%m%d')\n",
    "  with open('mapTimeSeries_'+layer+'_'+ANNname+'.csv','w') as outts:\n",
    "    outts.write(\"ID,maxLabel,Long,Lat\")\n",
    "    for day in range(0,365):\n",
    "      outts.write(\",\"+(startday + datetime.timedelta(days = day)).strftime(\"%Y%m%d\"))\n",
    "    outts.write(\"\\n\")\n",
    "    for ID in range(1,301):\n",
    "      (ID,Stratum,Long,Lat,zone,x,y,pixel,pline,centxUTM,centyUTM,MGRS) = sampleFull[str(ID)].split(',')\n",
    "      with open(outfolder + '/'+ID+'_DIST-ALERT_'+ANNname+'.csv','r') as map:\n",
    "        grans = map.readlines()[1:]\n",
    "      dates = [\"20210930\"]\n",
    "      labels = [nodatavalue]\n",
    "      maxlabel = -1000\n",
    "      daily = []\n",
    "      for g in grans:\n",
    "        fields = g.strip().split(',') #(gID,sensingTime,ProductionTime,VEG_DIST_STATUS,VEG_ANOM,VEG_IND,VEG_DIST_CONF,VEG_DIST_DATE,\tVEG_DIST_DUR,GEN_DIST_STATUS,GEN_ANOM,GEN_DIST_CONF,GEN_DIST_DATE,GEN_DIST_DUR)\n",
    "        value = fields[layerIndex]\n",
    "        if value == \"\":\n",
    "          value = \"NA\"\n",
    "        dates.append(fields[1])\n",
    "        labels.append(value)\n",
    "        if value != \"NA\" and int(value) != int(nodatavalue) and int(value) != -2 and int(value) != 200 and int(value) > maxlabel:\n",
    "          maxlabel = int(value)\n",
    "      dates.append(\"20221001\")\n",
    "      labels.append(nodatavalue)\n",
    "      i = 0\n",
    "      for day in range(0,365):\n",
    "        if datetime.datetime.strptime(dates[i],'%Y%m%d') < startday + datetime.timedelta(days = day):\n",
    "          while datetime.datetime.strptime(dates[i],'%Y%m%d') < startday + datetime.timedelta(days = day):\n",
    "            i+=1        \n",
    "        if datetime.datetime.strptime(dates[i],'%Y%m%d') == startday + datetime.timedelta(days = day):\n",
    "          daily.append(labels[i])\n",
    "          i += 1\n",
    "        elif datetime.datetime.strptime(dates[i],'%Y%m%d') > startday + datetime.timedelta(days = day):\n",
    "          daily.append(nodatavalue)         \n",
    "      outts.write(','.join([ID,str(maxlabel),Long,Lat]))\n",
    "      for d in daily:\n",
    "        outts.write(\",\"+d)\n",
    "      outts.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRefTimeSeries(suffix):\n",
    "  with open('reference'+suffix+'.csv','r') as file:\n",
    "    lines = file.readlines()\n",
    "  startday = datetime.datetime.strptime('20211001','%Y%m%d')\n",
    "  with open('referenceTimeSeries'+suffix+'.csv','w') as outts:\n",
    "    outts.write(\"ID,overallLabel,Long,Lat,changetype\")\n",
    "    for day in range(0,365):\n",
    "      outts.write(\",\"+(startday + datetime.timedelta(days = day)).strftime(\"%Y%m%d\"))\n",
    "    outts.write(\"\\n\")\n",
    "    for ID in range(1,301):\n",
    "      fields = lines[ID].strip().split(',')\n",
    "      (ID,person,overallLabel,Long,Lat,UTMzone,centxUTM,centyUTM,changetype) = fields[0:9]\n",
    "      fields = fields[9:]\n",
    "      dates = [\"20210930\"]\n",
    "      labels = [\"noObs\"]\n",
    "      daily = []\n",
    "      for period in range(0,73):\n",
    "        dates.append(fields[period*2])\n",
    "        labels.append(fields[period*2+1])\n",
    "      dates.append(\"20221001\")\n",
    "      labels.append(\"noObs\")\n",
    "      i = 0\n",
    "      for day in range(0,365):\n",
    "        while dates[i] == \"NA\":\n",
    "          i+=1\n",
    "        if datetime.datetime.strptime(dates[i],'%Y%m%d') == startday + datetime.timedelta(days = day):\n",
    "          daily.append(labels[i])\n",
    "          i += 1\n",
    "        elif datetime.datetime.strptime(dates[i],'%Y%m%d') > startday + datetime.timedelta(days = day):\n",
    "          if labels[i-1] == labels[i]:\n",
    "            daily.append(labels[i])\n",
    "          else:\n",
    "            daily.append(\"noObs\")\n",
    "        elif datetime.datetime.strptime(dates[i],'%Y%m%d') < startday + datetime.timedelta(days = day):\n",
    "          if labels[i] == labels[i+1]:\n",
    "            daily.append(labels[i])\n",
    "          else:\n",
    "            daily.append(\"noObs\")\n",
    "          i+=1\n",
    "          \n",
    "      outts.write(','.join([ID,overallLabel,Long,Lat,changetype]))\n",
    "      for d in daily:\n",
    "        outts.write(\",\"+d)\n",
    "      outts.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makeRefTimeSeries('_last')\n",
    "makeMapTimeSeriesDaily('VEG-DIST-STATUS',255)\n",
    "#makeMapTimeSeriesDaily('GEN-DIST-STATUS',255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
